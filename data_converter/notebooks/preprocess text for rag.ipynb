{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "52e08bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "a6046399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7303e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d48d855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "3a15576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean XMLs\n",
    "\n",
    "def xml_cleaner(file):\n",
    "    newfile = re.sub('doctest_block', 'paragraph', file)\n",
    "    newfile = re.sub('<\\/?(emphasis|inline|literal|reference|literal_block).*?>', '', newfile)\n",
    "    return newfile\n",
    "\n",
    "def clean_xmls(root):\n",
    "    nufiles = 0\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xml\"):\n",
    "                nufiles += 1\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                xml_file = open(file_path, 'r').read()\n",
    "                open(file_path, 'w').write(xml_cleaner(xml_file))\n",
    "        print(f\"Total files cleaned: {nufiles}\")\n",
    "\n",
    "def xml_to_json(input_dir, output_dir):\n",
    "    for subdir, dirs, files in os.walk(input_dir):\n",
    "        out_subdir = \"/\".join(output_dir.split(\"/\")[:3]+subdir.split(\"/\")[3:])\n",
    "        for file in files:\n",
    "            if file.endswith(\".xml\"):\n",
    "                in_file_path = os.path.join(subdir, file)\n",
    "                out_file_path = os.path.join(out_subdir, file)[:-3]+'json'\n",
    "#                 print(out_file_pathout_file_path[:-3]+'json')\n",
    "                os.makedirs(\"/\".join(out_file_path.split('/')[:-1]), exist_ok=True)\n",
    "                parse.runner(in_file_path, out_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "ec9ced9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files cleaned: 6\n",
      "Total files cleaned: 23\n",
      "Total files cleaned: 24\n",
      "Total files cleaned: 25\n",
      "Total files cleaned: 34\n",
      "Total files cleaned: 35\n",
      "Total files cleaned: 42\n",
      "Total files cleaned: 355\n",
      "Total files cleaned: 378\n",
      "Total files cleaned: 379\n",
      "Total files cleaned: 386\n",
      "Total files cleaned: 407\n",
      "Total files cleaned: 471\n",
      "Total files cleaned: 482\n"
     ]
    }
   ],
   "source": [
    "clean_xmls('../data/xml_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "4fcff638",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_to_json('../data/xml_files', '../data/json_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "8e3a8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUBBISH = ['@']\n",
    "\n",
    "def clean(text):\n",
    "    return re.sub('^\\s+|\\s+$|\\s+(?=\\s)', ' ', text.strip())\n",
    "\n",
    "def parse_dict_to_list(d, level=None, curr_level=0):\n",
    "    result = []\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, str) and k[0] not in RUBBISH:\n",
    "                result.append([k, clean(v)])\n",
    "            elif isinstance(v, list):\n",
    "                for item in v:\n",
    "                    if isinstance(item, str) and k[0] not in RUBBISH:\n",
    "                        result.append([k, clean(item)])\n",
    "                    else:\n",
    "                        sub_result = parse_dict_to_list(item, level, curr_level + 1)\n",
    "                        if curr_level < level:\n",
    "                            result.extend(sub_result)\n",
    "                        else:\n",
    "                            result.append([k, ' '.join([text for _, text in sub_result])])\n",
    "            else:\n",
    "                sub_result = parse_dict_to_list(v, level, curr_level + 1)\n",
    "                result.extend(sub_result)\n",
    "        if curr_level==level:\n",
    "            result=[[d.get('title', ''), '. '.join([text for _, text in result])]]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "4d04dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_parsed_list(documents):\n",
    "    result = [x for x in documents if x[0]]\n",
    "    for item in result:\n",
    "        item[1] = re.sub('(\\.\\s?\\.\\s?)+', '. ', item[1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "25815c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propogate_dataset(dataset, documents):\n",
    "    pd_docs = pd.DataFrame(clean_parsed_list(documents), columns=['title', 'text'])\n",
    "    return pd.concat([dataset, pd_docs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "8d527744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_jsons(root, dataset):\n",
    "    nufiles = 0\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                nufiles += 1\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                json_file = json.loads(open(file_path, 'r').read())\n",
    "                documents = parse_dict_to_list(json_file, level=3)\n",
    "                dataset = propogate_dataset(dataset, documents)\n",
    "        print(f\"Total files: {nufiles}\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "027ec7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 6\n",
      "Total files: 23\n",
      "Total files: 24\n",
      "Total files: 25\n",
      "Total files: 34\n",
      "Total files: 35\n",
      "Total files: 42\n",
      "Total files: 355\n",
      "Total files: 378\n",
      "Total files: 379\n",
      "Total files: 386\n",
      "Total files: 407\n",
      "Total files: 471\n",
      "Total files: 482\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame([], columns=['title', 'text'])\n",
    "dataset = parse_all_jsons('../data/json_files/', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "2116d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(dataset[dataset.title.isin(['paragraph', 'title', 'Important'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "16e79603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Documentation bugs</td>\n",
       "      <td>Documentation bugs. If you find a bug in this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Using the Python issue tracker</td>\n",
       "      <td>Using the Python issue tracker. Issue reports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Getting started contributing to Python yourself</td>\n",
       "      <td>Getting started contributing to Python yoursel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>History of the software</td>\n",
       "      <td>History of the software. Python was created in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Terms and conditions for accessing or otherwis...</td>\n",
       "      <td>Terms and conditions for accessing or otherwis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>Identifiers and keywords</td>\n",
       "      <td>Identifiers and keywords. . Identifiers (also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>Literals</td>\n",
       "      <td>Literals. Literals are notations for constant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>Operators</td>\n",
       "      <td>Operators. . The following tokens are operator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>Delimiters</td>\n",
       "      <td>Delimiters. The following tokens serve as deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>#text</td>\n",
       "      <td># PEG grammar for Python \\n@trailer '''\\nvoid ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1926 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   \n",
       "4                                    Documentation bugs  \\\n",
       "5                        Using the Python issue tracker   \n",
       "6       Getting started contributing to Python yourself   \n",
       "9                               History of the software   \n",
       "10    Terms and conditions for accessing or otherwis...   \n",
       "...                                                 ...   \n",
       "3705                           Identifiers and keywords   \n",
       "3706                                           Literals   \n",
       "3707                                          Operators   \n",
       "3708                                         Delimiters   \n",
       "3711                                              #text   \n",
       "\n",
       "                                                   text  \n",
       "4     Documentation bugs. If you find a bug in this ...  \n",
       "5     Using the Python issue tracker. Issue reports ...  \n",
       "6     Getting started contributing to Python yoursel...  \n",
       "9     History of the software. Python was created in...  \n",
       "10    Terms and conditions for accessing or otherwis...  \n",
       "...                                                 ...  \n",
       "3705  Identifiers and keywords. . Identifiers (also ...  \n",
       "3706  Literals. Literals are notations for constant ...  \n",
       "3707  Operators. . The following tokens are operator...  \n",
       "3708  Delimiters. The following tokens serve as deli...  \n",
       "3711  # PEG grammar for Python \\n@trailer '''\\nvoid ...  \n",
       "\n",
       "[1926 rows x 2 columns]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "19508a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text'], dtype='object')"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "edfe426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.astype(str).to_parquet('dataset_cpython.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e398d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f7e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f79ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41563bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021e0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
